{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5993f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Attach IUPred2A and PSSM features to the master BioPDB feature table.\n",
    "Outputs one CSV with every residue row plus the new feature columns.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11224dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────── paths ────────────────────────────\n",
    "master_in   = Path(\"../data/processed/BioPDB_features_with_labels_renumonly.csv\")\n",
    "iupred_in   = Path(\"../data/processed/iupred2a_scores_all.csv\")\n",
    "pssm_in     = Path(\"../data/processed/pssm_features_all.csv\")\n",
    "\n",
    "master_out  = Path(\"../data/processed/BioPDB_master_w_iupred_pssm.csv\")\n",
    "\n",
    "chunksize   = 1_000_000            # tweak to fit your RAM\n",
    "cat_dtype   = {\"pdb_id\":\"category\", \"chain_id\":\"category\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5e14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IUPred2A feature table …\n"
     ]
    }
   ],
   "source": [
    "# ────────────────── 1) load IUPred2A & PSSM once ──────────────────\n",
    "print(\"Loading IUPred2A feature table …\")\n",
    "iupred = pd.read_csv(\n",
    "    iupred_in,\n",
    "    dtype={**cat_dtype,\n",
    "           \"position\":\"int32\",\n",
    "           \"iupred2a_long_score\":\"float32\",\n",
    "           \"iupred2a_short_score\":\"float32\",\n",
    "           \"iupred2a_anchor_score\":\"float32\"}\n",
    ").rename(columns={\"position\":\"renum_residue_number\"})           # key harmonised\n",
    "iupred.set_index([\"pdb_id\",\"chain_id\",\"renum_residue_number\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795a5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PSSM feature table …\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading PSSM feature table …\")\n",
    "pssm = pd.read_csv(\n",
    "    pssm_in,\n",
    "    dtype={**cat_dtype,\n",
    "           \"position\":\"int32\",\n",
    "           \"chain\":\"category\"}       # chain → category\n",
    ").rename(columns={\"position\":\"renum_residue_number\",\n",
    "                  \"chain\":\"chain_id\"})\n",
    "pssm.set_index([\"pdb_id\",\"chain_id\",\"renum_residue_number\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878650a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop columns we don’t need to avoid bloat (keep position/AA to the left)\n",
    "# pssm_cols_to_keep = [col for col in pssm.columns if col.startswith(\"PSSM_\")]\n",
    "# pssm = pssm[pssm_cols_to_keep]\n",
    "# ── drop duplicate ID column to avoid name collision\n",
    "pssm = pssm.drop(columns=[\"amino_acid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────── 2) stream-merge master chunks ─────────────────\n",
    "if master_out.exists():\n",
    "    master_out.unlink()              # start fresh\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    master_in,\n",
    "    dtype={**cat_dtype, \"renum_residue_number\":\"int32\"},\n",
    "    chunksize=chunksize\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0112487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: wrote 1,000,000 rows\n",
      "Chunk 2: wrote 1,000,000 rows\n",
      "Chunk 3: wrote 1,003,423 rows\n",
      "Chunk 4: wrote 1,000,183 rows\n",
      "Chunk 5: wrote 1,019,624 rows\n",
      "Chunk 6: wrote 1,010,293 rows\n",
      "Chunk 7: wrote 1,017,832 rows\n",
      "Chunk 8: wrote 1,004,786 rows\n",
      "Chunk 9: wrote 1,026,902 rows\n",
      "Chunk 10: wrote 1,028,253 rows\n",
      "Chunk 11: wrote 1,009,718 rows\n",
      "Chunk 12: wrote 1,017,516 rows\n",
      "Chunk 13: wrote 1,012,947 rows\n",
      "Chunk 14: wrote 32,634 rows\n",
      "\n",
      "✓ All chunks processed.\n",
      "Augmented master file saved to: ../data/processed/BioPDB_master_w_iupred_pssm.csv\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(reader, 1):\n",
    "    # set same index for join\n",
    "    chunk.set_index([\"pdb_id\",\"chain_id\",\"renum_residue_number\"], inplace=True)\n",
    "\n",
    "    # merge (aligns on index)\n",
    "    chunk = chunk.join(iupred, how=\"left\")\n",
    "    chunk = chunk.join(pssm,   how=\"left\")\n",
    "\n",
    "    # reset index for output\n",
    "    chunk.reset_index(inplace=True)\n",
    "\n",
    "    # write\n",
    "    chunk.to_csv(\n",
    "        master_out,\n",
    "        mode=\"a\",\n",
    "        header=(i == 1),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Chunk {i}: wrote {len(chunk):,} rows\")\n",
    "\n",
    "print(\"\\n✓ All chunks processed.\")\n",
    "print(\"Augmented master file saved to:\", master_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3d92f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────── paths ───────────────\n",
    "master_in       = Path(\"../data/processed/BioPDB_master_w_iupred_pssm.csv\")\n",
    "dssp_in         = Path(\"../data/processed/dssp_residue_features_ALL.csv\")       # adjust if needed\n",
    "master_out      = Path(\"../data/processedmaster_residue_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "032c93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize       = 1_000_000        # rows per chunk; tweak for your RAM\n",
    "cat_dtype       = {\"pdb_id\": \"category\", \"chain_id\": \"category\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a603841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DSSP features …\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "# 1) Load DSSP once, convert residue_id → numeric pdb_residue_number\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "print(\"Loading DSSP features …\")\n",
    "\n",
    "def numeric_part(label: str) -> int:\n",
    "    \"\"\"Return integer part of author residue label (e.g. '150A' → 150).\"\"\"\n",
    "    return int(re.match(r\"-?\\d+\", str(label)).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee38d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssp = pd.read_csv(\n",
    "    dssp_in,\n",
    "    dtype={**cat_dtype, \"residue_id\": \"string\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d0e9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dssp[\"pdb_residue_number\"] = dssp[\"residue_id\"].map(numeric_part).astype(\"int32\")\n",
    "dssp = dssp.drop(columns=[\"residue_id\"])          # no longer needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b06d6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid column collision with master (rename if already present)\n",
    "if \"residue_name\" in dssp.columns:\n",
    "    dssp = dssp.rename(columns={\"residue_name\": \"dssp_residue_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68527c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → DSSP rows: 31234239\n"
     ]
    }
   ],
   "source": [
    "# set index for fast join\n",
    "dssp.set_index([\"pdb_id\", \"chain_id\", \"pdb_residue_number\"], inplace=True)\n",
    "print(\"  → DSSP rows:\", len(dssp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c7d4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────\n",
    "# 2) Stream-merge master chunks with DSSP and write output\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "if master_out.exists():\n",
    "    master_out.unlink()             # start fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de67cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv(\n",
    "    master_in,\n",
    "    dtype={**cat_dtype, \"pdb_residue_number\": \"int32\"},\n",
    "    chunksize=chunksize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ce0b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: wrote 1,006,545 rows\n",
      "Chunk 2: wrote 1,003,060 rows\n",
      "Chunk 3: wrote 1,003,112 rows\n",
      "Chunk 4: wrote 1,002,506 rows\n",
      "Chunk 5: wrote 1,002,408 rows\n",
      "Chunk 6: wrote 1,003,018 rows\n",
      "Chunk 7: wrote 1,003,338 rows\n",
      "Chunk 8: wrote 1,003,142 rows\n",
      "Chunk 9: wrote 1,002,954 rows\n",
      "Chunk 10: wrote 1,001,160 rows\n",
      "Chunk 11: wrote 1,002,079 rows\n",
      "Chunk 12: wrote 1,001,912 rows\n",
      "Chunk 13: wrote 1,000,262 rows\n",
      "Chunk 14: wrote 184,175 rows\n",
      "\n",
      "✓ All chunks processed.\n",
      "Final augmented file saved to: /home/mpradhan007/Academic/Research_Projects/Intern_Research/data/processedmaster_residue_file.csv\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(reader, 1):\n",
    "    # set same index as DSSP\n",
    "    chunk.set_index([\"pdb_id\", \"chain_id\", \"pdb_residue_number\"], inplace=True)\n",
    "\n",
    "    # left-join DSSP features\n",
    "    chunk = chunk.join(dssp, how=\"left\")\n",
    "\n",
    "    # reset index so identifiers are normal columns again\n",
    "    chunk.reset_index(inplace=True)\n",
    "\n",
    "    # append to output CSV\n",
    "    chunk.to_csv(\n",
    "        master_out,\n",
    "        mode=\"a\",\n",
    "        header=(i == 1),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Chunk {i}: wrote {len(chunk):,} rows\")\n",
    "\n",
    "print(\"\\n✓ All chunks processed.\")\n",
    "print(\"Final augmented file saved to:\", master_out.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d78932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomodeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
