{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681afa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpradhan007/anaconda3/envs/biomodeling/lib/python3.11/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "from Bio import SeqIO, pairwise2\n",
    "from Bio.PDB import MMCIFParser, PPBuilder\n",
    "from Bio.Align import substitution_matrices\n",
    "import csv, sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import MMCIFParser, Polypeptide\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO, pairwise2\n",
    "from Bio.PDB import MMCIFParser, PPBuilder, PDBList\n",
    "from Bio.Align import substitution_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6688ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1.  I/O locations\n",
    "# ---------------------------------------------------------------------------\n",
    "BIO_LIP_FILE = Path(\"../data/raw/BioLiP_nr.txt\")\n",
    "CIF_DIR      = Path(\"../data/raw/structures_cif\")\n",
    "FASTA_DIR    = Path(\"../data/raw/iupred_fasta\")\n",
    "OUT_FILE     = Path(\"../data/processed/processed_mapping/map_pdb_biolip_renum_residue_number_4.csv\")\n",
    "OUT_FILE.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca63553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 2.  Load BioLiP and list unique (pdb_id, chain) pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "cols = [\n",
    "    \"pdb_id\",\"receptor_chain\",\"resolution\",\"binding_site_id\",\"ligand_id\",\n",
    "    \"ligand_chain\",\"ligand_serial_number\",\"binding_residues_pdb\",\n",
    "    \"binding_residues_renum\",\"catalytic_residues_pdb\",\"catalytic_residues_renum\",\n",
    "    \"ec_number\",\"go_terms\",\"binding_affinity_literature\",\"binding_affinity_moad\",\n",
    "    \"binding_affinity_pdbbind\",\"binding_affinity_bindingdb\",\"uniprot_id\",\n",
    "    \"pubmed_id\",\"ligand_residue_seq_number\",\"receptor_sequence\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe372c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_436813/3354235033.py:1: DtypeWarning: Columns (13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  biolip_df = pd.read_csv(BIO_LIP_FILE, sep=\"\\t\", header=None, names=cols)\n"
     ]
    }
   ],
   "source": [
    "biolip_df = pd.read_csv(BIO_LIP_FILE, sep=\"\\t\", header=None, names=cols)\n",
    "chain_pairs = (\n",
    "    biolip_df[[\"pdb_id\", \"receptor_chain\"]]\n",
    "    .drop_duplicates()\n",
    "    .itertuples(index=False, name=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9134093",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_pairs = list(chain_pairs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3a5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_pairs = chain_pairs[30000:]  # Limit to first 1000 pairs for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e818e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_structure(pdb_id: str, cif_dir=\"cifs\") -> Path:\n",
    "    \"\"\"Download the mmCIF if it is not already on disk and return its path.\"\"\"\n",
    "    Path(cif_dir).mkdir(exist_ok=True)\n",
    "    cif_path = Path(cif_dir) / f\"{pdb_id.lower()}.cif\"\n",
    "    if not cif_path.exists():\n",
    "        PDBList().retrieve_pdb_file(\n",
    "            pdb_code=pdb_id, file_format=\"mmCif\",\n",
    "            pdir=cif_dir, overwrite=False\n",
    "        )\n",
    "    return cif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5c120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_sequence(cif_path, chain_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Accepts either a str or Path; returns the one-letter sequence\n",
    "    for `chain_id` in the mmCIF file.\n",
    "    \"\"\"\n",
    "    path_obj = Path(cif_path)           # ← normalize to Path\n",
    "    parser   = MMCIFParser(QUIET=True)\n",
    "    structure = parser.get_structure(path_obj.stem, str(path_obj))\n",
    "\n",
    "    ppb = PPBuilder()\n",
    "    for model in structure:\n",
    "        try:\n",
    "            chain = model[chain_id]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Chain {chain_id} not found in {path_obj.name}\")\n",
    "        # Concatenate peptides that belong to this chain\n",
    "        seq = \"\".join(str(pp.get_sequence()) for pp in ppb.build_peptides(chain))\n",
    "        return seq\n",
    "\n",
    "    raise RuntimeError(\"No model found in the structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff0c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sequences(seq_pdb: str, seq_fasta: str):\n",
    "    \"\"\"Global alignment with BLOSUM62; returns alignment objects.\"\"\"\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "    alignments = pairwise2.align.globalds(seq_pdb, seq_fasta, blosum62, -11, -1)\n",
    "    # choose the top-scoring alignment\n",
    "    return alignments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc61caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mapping(aln_pdb, aln_fasta, residues):\n",
    "    \"\"\"\n",
    "    Given aligned strings and a list of (res_id, full_residue_obj),\n",
    "    return a list of rows with mapping between PDB residue id and FASTA index.\n",
    "    \"\"\"\n",
    "    mapping = []\n",
    "    pdb_idx = 0   # index in original PDB sequence\n",
    "    fas_idx = 0   # index in FASTA sequence\n",
    "    for a_pdb, a_fas, res in zip(aln_pdb, aln_fasta, residues):\n",
    "        if a_pdb != \"-\":   # residue exists in PDB chain\n",
    "            res_id = residues[pdb_idx][0]      # (resseq, icode) pair or residue.id\n",
    "            pdb_idx += 1\n",
    "        if a_fas != \"-\":\n",
    "            fas_idx += 1\n",
    "        if a_pdb != \"-\" and a_fas != \"-\":\n",
    "            mapping.append((res_id, fas_idx))   # 1-based indices\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd10834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
    "     'ALA': 'A', 'VAL': 'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748a6e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7fqi A\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7m2m A\n",
      "[warn] 7mqa nan: Chain nan not found in 7mqa.cif\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7n4y B\n",
      "[warn] alignment failed (list index out of range): 7nrc Lt\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7ntl A\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7p1o X\n",
      "[warn] 7pxo AAA: Chain AAA not found in 7pxo.cif\n",
      "[warn] alignment failed (list index out of range): 7qdi A\n",
      "[warn] alignment failed (list index out of range): 7y3f 6\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 7zon B\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 8af2 A\n",
      "[warn] 8ckb THA016: Chain THA016 not found in 8ckb.cif\n",
      "[warn] alignment failed (<built-in function _make_score_matrix_fast> returned a result with an exception set): 8g5y SX\n",
      "[warn] alignment failed (list index out of range): 8gqp A\n",
      "[warn] alignment failed (list index out of range): 8jh6 A\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "# 0-bis.  Build expected sequence lengths once  (outside the loop)\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "seq_len = {\n",
    "    (row.pdb_id.lower(), row.receptor_chain): len(row.receptor_sequence)\n",
    "    for row in biolip_df.itertuples(index=False)\n",
    "}\n",
    "\n",
    "# Decide whether we are appending or creating the CSV\n",
    "mode   = \"a\" if OUT_FILE.exists() else \"w\"\n",
    "header = mode == \"w\"\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "# 3.  Write / append mapping rows\n",
    "# ───────────────────────────────────────────────────────────────────────────\n",
    "with OUT_FILE.open(mode, newline=\"\") as fh:\n",
    "    writer = csv.writer(fh)\n",
    "    if header:\n",
    "        writer.writerow([\n",
    "            \"pdb_id\", \"chain_id\", \"pdb_residue_number\",\n",
    "            \"insertion_code\", \"aa\", \"renum_residue_number\"\n",
    "        ])\n",
    "\n",
    "    for pdb_id, chain_id in chain_pairs:\n",
    "        pdb_id_lc = pdb_id.lower()\n",
    "\n",
    "        # ───── heavy work starts here ─────\n",
    "        cif_path   = CIF_DIR / f\"{pdb_id_lc}.cif\"\n",
    "        fasta_path = FASTA_DIR / f\"{pdb_id}_{chain_id}.fasta\"\n",
    "        if not (cif_path.exists() and fasta_path.exists()):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pdb_seq = chain_sequence(cif_path, chain_id)\n",
    "        except Exception as err:\n",
    "            print(f\"[warn] {pdb_id} {chain_id}: {err}\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        fasta_seq = str(next(SeqIO.parse(fasta_path, \"fasta\")).seq)\n",
    "        try:\n",
    "            aln_pdb, aln_fas, *_ = align_sequences(pdb_seq, fasta_seq)\n",
    "        except (IndexError, ValueError, SystemError) as e:\n",
    "            print(f\"[warn] alignment failed ({e}): {pdb_id} {chain_id}\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        structure = MMCIFParser(QUIET=True).get_structure(pdb_id_lc, cif_path)\n",
    "        residues  = [\n",
    "            (res.id, res) for res in structure[0][chain_id]\n",
    "            if Polypeptide.is_aa(res, standard=True)\n",
    "        ]\n",
    "\n",
    "        id_to_aa = {res.id: d.get(res.get_resname().upper(), \"X\")\n",
    "                    for (_, res) in residues}\n",
    "\n",
    "        for res_id, renum in build_mapping(aln_pdb, aln_fas, residues):\n",
    "            het, auth_num, icode = res_id\n",
    "            icode_str  = icode.strip()\n",
    "            pdb_number = f\"{auth_num}{icode_str}\"\n",
    "            aa = id_to_aa.get(res_id, \"X\")\n",
    "            writer.writerow([\n",
    "                pdb_id_lc, chain_id, pdb_number,\n",
    "                icode_str, aa, renum\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3828b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------------------\n",
    "# # 3.  Write mapping rows to CSV\n",
    "# # ---------------------------------------------------------------------------\n",
    "# with OUT_FILE.open(\"w\", newline=\"\") as fh:\n",
    "#     writer = csv.writer(fh)\n",
    "#     writer.writerow([\n",
    "#         \"pdb_id\", \"chain_id\", \"pdb_residue_number\",\n",
    "#         \"insertion_code\", \"aa\", \"renum_residue_number\"\n",
    "#     ])\n",
    "\n",
    "#     for pdb_id, chain_id in chain_pairs:\n",
    "#         pdb_id_lc  = pdb_id.lower()                       # keep lower-case\n",
    "#         cif_path   = CIF_DIR / f\"{pdb_id_lc}.cif\"\n",
    "#         fasta_path = FASTA_DIR / f\"{pdb_id}_{chain_id}.fasta\"\n",
    "\n",
    "#         if not (cif_path.exists() and fasta_path.exists()):\n",
    "#             continue  # skip chains whose files are missing\n",
    "\n",
    "#         try:\n",
    "#             pdb_seq = chain_sequence(cif_path, chain_id)  # helper unchanged\n",
    "#         except Exception as err:\n",
    "#             print(f\"[warn] {pdb_id} {chain_id}: {err}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         fasta_seq = str(next(SeqIO.parse(fasta_path, \"fasta\")).seq)\n",
    "#         try:\n",
    "#             aln_pdb, aln_fas, *_ = align_sequences(pdb_seq, fasta_seq)\n",
    "#         except (IndexError, ValueError):          # no alignment or bad chars\n",
    "#             print(f\"[warn] alignment failed: {pdb_id} {chain_id}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         parser    = MMCIFParser(QUIET=True)\n",
    "#         structure = parser.get_structure(pdb_id_lc, cif_path)\n",
    "#         residues  = [\n",
    "#             (res.id, res) for res in structure[0][chain_id]\n",
    "#             if Polypeptide.is_aa(res, standard=True)\n",
    "#         ]\n",
    "\n",
    "#         id_to_aa = {\n",
    "#             res.id: d.get(res.get_resname().upper(), \"X\")\n",
    "#             for (_, res) in residues\n",
    "#         }\n",
    "        \n",
    "\n",
    "#         for res_id, renum in build_mapping(aln_pdb, aln_fas, residues):\n",
    "#             het, auth_num, icode = res_id\n",
    "#             icode_str   = icode.strip()               # '' if blank\n",
    "#             pdb_number  = f\"{auth_num}{icode_str}\"\n",
    "#             try:\n",
    "#                 # if len(auth_num) < 3:\n",
    "#                 #     print(\"not working\")\n",
    "#                 # aa = d.get(residues[auth_num][1].get_resname(), \"X\")\n",
    "#                 aa = id_to_aa.get(res_id, \"X\") \n",
    "#             except KeyError:\n",
    "#                 aa = \"X\"                             # non-standard amino acid\n",
    "#             writer.writerow([\n",
    "#                 pdb_id_lc, chain_id, pdb_number,\n",
    "#                 icode_str, aa, renum\n",
    "#             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf51be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick helper --------------------------------------------------------------\n",
    "# def chain_done(pdb_lc, chain, out_csv, need):\n",
    "#     \"\"\"\n",
    "#     Return True if `out_csv` already contains at least `need` rows\n",
    "#     for (pdb_lc, chain).  Uses on-disk chunked filtering, so RAM stays tiny.\n",
    "#     \"\"\"\n",
    "#     if not out_csv.exists():\n",
    "#         return False\n",
    "#     seen = 0\n",
    "#     for chunk in pd.read_csv(out_csv, usecols=[\"pdb_id\", \"chain_id\"],\n",
    "#                              chunksize=50_000):\n",
    "#         mask = (chunk[\"pdb_id\"] == pdb_lc) & (chunk[\"chain_id\"] == chain)\n",
    "#         seen += mask.sum()\n",
    "#         if seen >= need:\n",
    "#             return True\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ───────────────────────────────────────────────────────────────────────────\n",
    "# # 0-bis.  Build expected sequence lengths once  (outside the loop)\n",
    "# # ───────────────────────────────────────────────────────────────────────────\n",
    "# seq_len = {\n",
    "#     (row.pdb_id.lower(), row.receptor_chain): len(row.receptor_sequence)\n",
    "#     for row in biolip_df.itertuples(index=False)\n",
    "# }\n",
    "\n",
    "# # Decide whether we are appending or creating the CSV\n",
    "# mode   = \"a\" if OUT_FILE.exists() else \"w\"\n",
    "# header = mode == \"w\"\n",
    "\n",
    "# # ───────────────────────────────────────────────────────────────────────────\n",
    "# # 3.  Write / append mapping rows\n",
    "# # ───────────────────────────────────────────────────────────────────────────\n",
    "# with OUT_FILE.open(mode, newline=\"\") as fh:\n",
    "#     writer = csv.writer(fh)\n",
    "#     if header:\n",
    "#         writer.writerow([\n",
    "#             \"pdb_id\", \"chain_id\", \"pdb_residue_number\",\n",
    "#             \"insertion_code\", \"aa\", \"renum_residue_number\"\n",
    "#         ])\n",
    "\n",
    "#     for pdb_id, chain_id in chain_pairs:\n",
    "#         pdb_id_lc = pdb_id.lower()\n",
    "\n",
    "#         # Fast pre-check: skip if chain already fully mapped\n",
    "#         need = seq_len.get((pdb_id_lc, chain_id))          # None → keep going\n",
    "#         if need and chain_done(pdb_id_lc, chain_id, OUT_FILE, need):\n",
    "#             continue\n",
    "\n",
    "#         # ───── heavy work from here onward (unchanged) ─────\n",
    "#         cif_path   = CIF_DIR / f\"{pdb_id_lc}.cif\"\n",
    "#         fasta_path = FASTA_DIR / f\"{pdb_id}_{chain_id}.fasta\"\n",
    "#         if not (cif_path.exists() and fasta_path.exists()):\n",
    "#             continue\n",
    "\n",
    "#         try:\n",
    "#             pdb_seq = chain_sequence(cif_path, chain_id)\n",
    "#         except Exception as err:\n",
    "#             print(f\"[warn] {pdb_id} {chain_id}: {err}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         fasta_seq = str(next(SeqIO.parse(fasta_path, \"fasta\")).seq)\n",
    "#         try:\n",
    "#             aln_pdb, aln_fas, *_ = align_sequences(pdb_seq, fasta_seq)\n",
    "#         except (IndexError, ValueError):\n",
    "#             print(f\"[warn] alignment failed: {pdb_id} {chain_id}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         structure = MMCIFParser(QUIET=True).get_structure(pdb_id_lc, cif_path)\n",
    "#         residues  = [\n",
    "#             (res.id, res) for res in structure[0][chain_id]\n",
    "#             if Polypeptide.is_aa(res, standard=True)\n",
    "#         ]\n",
    "\n",
    "#         id_to_aa = {res.id: d.get(res.get_resname().upper(), \"X\")\n",
    "#                     for (_, res) in residues}\n",
    "\n",
    "#         for res_id, renum in build_mapping(aln_pdb, aln_fas, residues):\n",
    "#             het, auth_num, icode = res_id\n",
    "#             icode_str  = icode.strip()\n",
    "#             pdb_number = f\"{auth_num}{icode_str}\"\n",
    "#             aa = id_to_aa.get(res_id, \"X\")\n",
    "#             writer.writerow([\n",
    "#                 pdb_id_lc, chain_id, pdb_number,\n",
    "#                 icode_str, aa, renum\n",
    "#             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9e1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------------------\n",
    "# # 3.  Write mapping rows to CSV\n",
    "# # ---------------------------------------------------------------------------\n",
    "# with OUT_FILE.open(\"w\", newline=\"\") as fh:\n",
    "#     writer = csv.writer(fh)\n",
    "#     writer.writerow([\n",
    "#         \"pdb_id\", \"chain_id\", \"pdb_residue_number\",\n",
    "#         \"insertion_code\", \"aa\", \"renum_residue_number\"\n",
    "#     ])\n",
    "\n",
    "#     for pdb_id, chain_id in chain_pairs:\n",
    "#         pdb_id_lc  = pdb_id.lower()                       # keep lower-case\n",
    "\n",
    "#         seq_len = {\n",
    "#             (row.pdb_id.lower(), row.receptor_chain): len(row.receptor_sequence)\n",
    "#             for row in biolip_df.itertuples(index=False)\n",
    "#         }\n",
    "\n",
    "#         # ---------- FAST pre-check: is the chain already fully mapped? ------\n",
    "#         need = seq_len.get((pdb_id, chain_id))  # could be None if missing\n",
    "#         if need and chain_done(pdb_id_lc, chain_id, OUT_FILE, need):\n",
    "#             continue\n",
    "\n",
    "\n",
    "#         cif_path   = CIF_DIR / f\"{pdb_id_lc}.cif\"\n",
    "#         fasta_path = FASTA_DIR / f\"{pdb_id}_{chain_id}.fasta\"\n",
    "\n",
    "#         if not (cif_path.exists() and fasta_path.exists()):\n",
    "#             continue  # skip chains whose files are missing\n",
    "\n",
    "#         try:\n",
    "#             pdb_seq = chain_sequence(cif_path, chain_id)  # helper unchanged\n",
    "#         except Exception as err:\n",
    "#             print(f\"[warn] {pdb_id} {chain_id}: {err}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         fasta_seq = str(next(SeqIO.parse(fasta_path, \"fasta\")).seq)\n",
    "#         try:\n",
    "#             aln_pdb, aln_fas, *_ = align_sequences(pdb_seq, fasta_seq)\n",
    "#         except (IndexError, ValueError):          # no alignment or bad chars\n",
    "#             print(f\"[warn] alignment failed: {pdb_id} {chain_id}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         parser    = MMCIFParser(QUIET=True)\n",
    "#         structure = parser.get_structure(pdb_id_lc, cif_path)\n",
    "#         residues  = [\n",
    "#             (res.id, res) for res in structure[0][chain_id]\n",
    "#             if Polypeptide.is_aa(res, standard=True)\n",
    "#         ]\n",
    "\n",
    "#         id_to_aa = {\n",
    "#             res.id: d.get(res.get_resname().upper(), \"X\")\n",
    "#             for (_, res) in residues\n",
    "#         }\n",
    "        \n",
    "\n",
    "#         for res_id, renum in build_mapping(aln_pdb, aln_fas, residues):\n",
    "#             het, auth_num, icode = res_id\n",
    "#             icode_str   = icode.strip()               # '' if blank\n",
    "#             pdb_number  = f\"{auth_num}{icode_str}\"\n",
    "#             try:\n",
    "#                 # if len(auth_num) < 3:\n",
    "#                 #     print(\"not working\")\n",
    "#                 # aa = d.get(residues[auth_num][1].get_resname(), \"X\")\n",
    "#                 aa = id_to_aa.get(res_id, \"X\") \n",
    "#             except KeyError:\n",
    "#                 aa = \"X\"                             # non-standard amino acid\n",
    "#             writer.writerow([\n",
    "#                 pdb_id_lc, chain_id, pdb_number,\n",
    "#                 icode_str, aa, renum\n",
    "#             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78da66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------------------\n",
    "# # 3.  Write mapping rows to CSV\n",
    "# # ---------------------------------------------------------------------------\n",
    "# with OUT_FILE.open(\"w\", newline=\"\") as fh:\n",
    "#     writer = csv.writer(fh)\n",
    "#     writer.writerow([\n",
    "#         \"pdb_id\", \"chain_id\", \"pdb_residue_number\",\n",
    "#         \"insertion_code\", \"aa\", \"renum_residue_number\"\n",
    "#     ])\n",
    "\n",
    "#     for pdb_id, chain_id in chain_pairs:\n",
    "#         pdb_id_lc  = pdb_id.lower()                       # keep lower-case\n",
    "#         cif_path   = CIF_DIR / f\"{pdb_id_lc}.cif\"\n",
    "#         fasta_path = FASTA_DIR / f\"{pdb_id}_{chain_id}.fasta\"\n",
    "\n",
    "#         if not (cif_path.exists() and fasta_path.exists()):\n",
    "#             continue  # skip chains whose files are missing\n",
    "\n",
    "#         try:\n",
    "#             pdb_seq = chain_sequence(cif_path, chain_id)  # helper unchanged\n",
    "#         except Exception as err:\n",
    "#             print(f\"[warn] {pdb_id} {chain_id}: {err}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         fasta_seq = str(next(SeqIO.parse(fasta_path, \"fasta\")).seq)\n",
    "#         try:\n",
    "#             aln_pdb, aln_fas, *_ = align_sequences(pdb_seq, fasta_seq)\n",
    "#         except (IndexError, ValueError):          # no alignment or bad chars\n",
    "#             print(f\"[warn] alignment failed: {pdb_id} {chain_id}\", file=sys.stderr)\n",
    "#             continue\n",
    "\n",
    "#         parser    = MMCIFParser(QUIET=True)\n",
    "#         structure = parser.get_structure(pdb_id_lc, cif_path)\n",
    "#         residues  = [\n",
    "#             (res.id, res) for res in structure[0][chain_id]\n",
    "#             if Polypeptide.is_aa(res, standard=True)\n",
    "#         ]\n",
    "\n",
    "#         id_to_aa = {\n",
    "#             res.id: d.get(res.get_resname().upper(), \"X\")\n",
    "#             for (_, res) in residues\n",
    "#         }\n",
    "        \n",
    "\n",
    "#         for res_id, renum in build_mapping(aln_pdb, aln_fas, residues):\n",
    "#             het, auth_num, icode = res_id\n",
    "#             icode_str   = icode.strip()               # '' if blank\n",
    "#             pdb_number  = f\"{auth_num}{icode_str}\"\n",
    "#             try:\n",
    "#                 # if len(auth_num) < 3:\n",
    "#                 #     print(\"not working\")\n",
    "#                 # aa = d.get(residues[auth_num][1].get_resname(), \"X\")\n",
    "#                 aa = id_to_aa.get(res_id, \"X\") \n",
    "#             except KeyError:\n",
    "#                 aa = \"X\"                             # non-standard amino acid\n",
    "#             writer.writerow([\n",
    "#                 pdb_id_lc, chain_id, pdb_number,\n",
    "#                 icode_str, aa, renum\n",
    "#             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac18c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomodeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
