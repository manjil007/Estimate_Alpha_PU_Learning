{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Add BioLiP renum_residue_number to BioPDB_features_with_labels.csv\n",
    "   • Keys used: pdb_id, chain_id, pdb_residue_number\n",
    "   • Insertion codes are ignored.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ──────────────────────────── paths & parameters ────────────────────────────\n",
    "master_path   = Path(\"../data/processed/BioPDB_features_with_labels.csv\")\n",
    "mapping_path  = Path(\"../data/processed/map_pdb_biolip_renum_all.csv\")\n",
    "output_path   = Path(\"../data/processed/BioPDB_features_with_labels_w_renum.csv\")\n",
    "\n",
    "chunksize     = 500_000                       # tweak for your RAM\n",
    "cat_dtype     = {\"pdb_id\":\"category\", \"chain_id\":\"category\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d555f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────── 1) load mapping into RAM ───────────────────────\n",
    "print(\"Loading mapping …\")\n",
    "mapping = pd.read_csv(\n",
    "    mapping_path,\n",
    "    usecols=[\"pdb_id\", \"chain_id\", \"pdb_residue_number\", \"renum_residue_number\"],\n",
    "    dtype={**cat_dtype,\n",
    "           \"pdb_residue_number\":\"int32\",\n",
    "           \"renum_residue_number\":\"int32\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── ensure there is at most one renum per (pdb_id, chain_id, pdb_residue_number)\n",
    "mapping = mapping.drop_duplicates(\n",
    "    [\"pdb_id\", \"chain_id\", \"pdb_residue_number\"],\n",
    "    keep=\"first\"\n",
    ")\n",
    "dupes = mapping.duplicated([\"pdb_id\",\"chain_id\",\"pdb_residue_number\"], keep=False)\n",
    "if dupes.any():\n",
    "    raise ValueError(\n",
    "        \"Duplicate author numbers with different insertion codes detected:\\n\"\n",
    "        f\"{mapping.loc[dupes].head()}\\n\"\n",
    "        \"Decide how to handle these before merging.\"\n",
    "    )\n",
    "\n",
    "mapping.set_index([\"pdb_id\",\"chain_id\",\"pdb_residue_number\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────── 2) stream-merge master ─────────────────────────\n",
    "if output_path.exists():\n",
    "    output_path.unlink()                     # start fresh\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    master_path,\n",
    "    dtype={**cat_dtype, \"residue_number\":\"int32\"},\n",
    "    chunksize=chunksize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d91b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows, matched_rows = 0, 0\n",
    "\n",
    "for i, chunk in enumerate(reader, 1):\n",
    "    total_rows += len(chunk)\n",
    "\n",
    "    # rename to align with mapping keys\n",
    "    chunk = chunk.rename(columns={\"residue_number\":\"pdb_residue_number\"})\n",
    "\n",
    "    # join via index for speed\n",
    "    chunk = chunk.join(\n",
    "        mapping, on=[\"pdb_id\",\"chain_id\",\"pdb_residue_number\"]\n",
    "    )\n",
    "\n",
    "    matched_rows += chunk[\"renum_residue_number\"].notna().sum()\n",
    "\n",
    "    chunk.to_csv(\n",
    "        output_path,\n",
    "        mode=\"a\",\n",
    "        header=(i == 1),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Chunk {i}: processed {len(chunk):,} rows \"\n",
    "          f\"({chunk['renum_residue_number'].notna().mean():.1%} matched)\")\n",
    "\n",
    "print(\"──────────────────────── summary ────────────────────────\")\n",
    "print(f\"Total master rows   : {total_rows:,}\")\n",
    "print(f\"Rows with renum     : {matched_rows:,} \"\n",
    "      f\"({matched_rows/total_rows:.1%})\")\n",
    "print(\"Output written to   :\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ce249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Filtered file written to: ../data/processed/BioPDB_features_with_labels_renumonly.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "\n",
    "in_path  = Path(\"../data/processed/BioPDB_features_with_labels_w_renum.csv\")\n",
    "out_path = Path(\"../data/processed/BioPDB_features_with_labels_renumonly.csv\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_csv_auto('{in_path.resolve()}', header=True)\n",
    "        WHERE renum_residue_number IS NOT NULL      -- keep only mapped rows\n",
    "    )\n",
    "    TO '{out_path.resolve()}'\n",
    "    (HEADER, DELIMITER ',');\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Filtered file written to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182fe3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows processed : 13,032,634\n",
      "\n",
      "Missing-value count per column\n",
      "--------------------------------\n",
      "prev_res                 40577\n",
      "next_res                 35988\n",
      "closest_neighbor_dist        3\n",
      "avg_neighbor_distance        3\n",
      "pdb_id                       0\n",
      "chain_id                     0\n",
      "pdb_residue_number           0\n",
      "centroid_z                   0\n",
      "mean_bfactor                 0\n",
      "std_bfactor                  0\n",
      "mean_occupancy               0\n",
      "insertion_code               0\n",
      "residue_name                 0\n",
      "centroid_x                   0\n",
      "centroid_y                   0\n",
      "mean_intra_atom_dist         0\n",
      "num_sidechain_atoms          0\n",
      "num_heavy_atoms              0\n",
      "num_atoms                    0\n",
      "bounding_box_volume          0\n",
      "residue_radius               0\n",
      "radius_of_gyration           0\n",
      "std_intra_atom_dist          0\n",
      "position_in_chain            0\n",
      "is_small                     0\n",
      "contact_number_4A            0\n",
      "contact_number_6A            0\n",
      "contact_number_8A            0\n",
      "contact_number_10A           0\n",
      "label                        0\n",
      "renum_residue_number         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────── paths & parameters ─────────────\n",
    "in_path   = Path(\"../data/processed/BioPDB_features_with_labels_renumonly.csv\")\n",
    "chunksize = 1_000_000          # adjust to your RAM\n",
    "\n",
    "# ───────────── initialise running totals ───────\n",
    "na_counts   = None   # will become a pandas Series\n",
    "total_rows  = 0\n",
    "\n",
    "# ───────────── stream & accumulate ─────────────\n",
    "for chunk in pd.read_csv(in_path, chunksize=chunksize):\n",
    "    total_rows += len(chunk)\n",
    "    # count NAs in this chunk\n",
    "    chunk_na = chunk.isna().sum()\n",
    "\n",
    "    # first chunk → create Series; later chunks → add\n",
    "    na_counts = chunk_na if na_counts is None else na_counts.add(chunk_na, fill_value=0)\n",
    "\n",
    "# ───────────── report ─────────────\n",
    "print(f\"Total rows processed : {total_rows:,}\\n\")\n",
    "print(\"Missing-value count per column\")\n",
    "print(\"--------------------------------\")\n",
    "print(na_counts.astype(int).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64996c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomodeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
